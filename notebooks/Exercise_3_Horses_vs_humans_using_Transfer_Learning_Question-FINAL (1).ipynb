{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "lbFmQdsZs5eW"
   },
   "outputs": [],
   "source": [
    "# ATTENTION: Please do not alter any of the provided code in the exercise. Only add your own code where indicated\n",
    "# ATTENTION: Please do not add or remove any cells in the exercise. The grader will check specific cells based on the cell position.\n",
    "# ATTENTION: Please use the provided epoch values when training.\n",
    "\n",
    "# Import all the necessary files!\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import Model\n",
    "from os import getcwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "1xJZ5glPPCRz",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"inception_v3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 74, 74, 32)   96          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 74, 74, 32)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 72, 72, 32)   9216        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 72, 72, 32)   96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 72, 72, 32)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 72, 72, 64)   18432       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 72, 72, 64)   192         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 72, 72, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 35, 35, 80)   240         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 35, 35, 80)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 33, 33, 192)  138240      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 33, 33, 192)  576         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 33, 33, 192)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 16, 16, 64)   192         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 16, 16, 64)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 16, 16, 48)   9216        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 16, 16, 96)   55296       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 16, 16, 48)   144         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 16, 16, 96)   288         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16, 16, 48)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 16, 16, 96)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 16, 16, 64)   76800       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 16, 16, 96)   82944       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 16, 16, 64)   192         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 16, 16, 64)   192         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 16, 16, 96)   288         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 16, 16, 32)   96          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 16, 16, 64)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 16, 16, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 16, 16, 96)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 16, 16, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_57[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 16, 16, 64)   192         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 16, 16, 64)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 16, 16, 96)   55296       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 16, 16, 48)   144         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 16, 16, 96)   288         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 16, 16, 48)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 16, 16, 96)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 16, 64)   76800       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 16, 16, 96)   82944       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 16, 16, 64)   192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 16, 16, 64)   192         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 16, 16, 96)   288         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 16, 16, 64)   192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 16, 16, 64)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 16, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 16, 16, 96)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 16, 16, 64)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_64[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 16, 16, 64)   192         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 16, 16, 64)   0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 96)   55296       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 16, 16, 48)   144         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 16, 16, 96)   288         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 16, 16, 48)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 16, 16, 96)   0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 16, 64)   76800       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, 16, 96)   82944       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 16, 16, 64)   192         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 16, 16, 64)   192         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 16, 16, 96)   288         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 16, 16, 64)   192         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 16, 16, 64)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 16, 16, 64)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 16, 16, 96)   0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 16, 16, 64)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_71[0][0]              \n",
      "                                                                 activation_73[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 16, 16, 64)   192         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 16, 16, 64)   0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 16, 16, 96)   55296       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 16, 16, 96)   288         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 16, 16, 96)   0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 7, 7, 96)     82944       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 7, 7, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 7, 7, 96)     288         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 7, 7, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 7, 7, 96)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_81[0][0]              \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 7, 7, 128)    384         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 7, 7, 128)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 7, 7, 128)    114688      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 7, 7, 128)    384         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 7, 7, 128)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 7, 7, 128)    114688      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 7, 7, 128)    384         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 7, 7, 128)    384         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 7, 7, 128)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 7, 7, 128)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 7, 7, 128)    114688      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 7, 7, 128)    114688      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 7, 7, 128)    384         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 7, 7, 128)    384         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 7, 7, 128)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 7, 7, 128)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 7, 7, 192)    172032      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 7, 7, 192)    172032      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 7, 7, 192)    576         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 7, 7, 192)    576         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 7, 7, 192)    576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 7, 7, 192)    576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 7, 7, 192)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 7, 7, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 7, 192)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 7, 192)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "                                                                 activation_90[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 7, 7, 160)    480         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 7, 160)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 7, 7, 160)    179200      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 7, 7, 160)    480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 7, 160)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 7, 7, 160)    179200      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 7, 7, 160)    480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 7, 7, 160)    480         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 7, 160)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 7, 7, 160)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 7, 7, 160)    179200      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 7, 7, 160)    179200      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 7, 7, 160)    480         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 7, 7, 160)    480         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 7, 160)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 7, 7, 160)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 7, 7, 192)    215040      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 7, 7, 192)    215040      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 7, 7, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 7, 7, 192)    576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 7, 7, 192)    576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 7, 7, 192)    576         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 7, 192)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 7, 192)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 7, 7, 192)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 7, 7, 192)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "                                                                 activation_100[0][0]             \n",
      "                                                                 activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 7, 7, 160)    480         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 7, 7, 160)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 7, 7, 160)    179200      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 7, 7, 160)    480         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 7, 7, 160)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 7, 7, 160)    179200      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 7, 7, 160)    480         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 7, 7, 160)    480         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 7, 7, 160)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 7, 7, 160)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 7, 7, 160)    179200      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 7, 7, 160)    179200      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 7, 7, 160)    480         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 7, 7, 160)    480         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 7, 7, 160)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 7, 7, 160)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 7, 7, 192)    215040      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 7, 7, 192)    215040      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 7, 7, 192)    576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 7, 7, 192)    576         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 7, 7, 192)    576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 7, 7, 192)    576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 7, 7, 192)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 7, 7, 192)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 7, 7, 192)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 7, 7, 192)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_110[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 7, 7, 192)    576         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 7, 7, 192)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 7, 7, 192)    258048      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 7, 7, 192)    576         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 7, 7, 192)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 7, 7, 192)    258048      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 7, 7, 192)    576         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 7, 7, 192)    576         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 7, 7, 192)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 7, 7, 192)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 7, 7, 192)    258048      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 192)    258048      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 7, 7, 192)    576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 7, 7, 192)    576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 7, 7, 192)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 7, 7, 192)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 7, 7, 192)    258048      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 7, 7, 192)    258048      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 7, 7, 192)    576         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 7, 7, 192)    576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 7, 7, 192)    576         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 7, 7, 192)    576         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 7, 7, 192)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 7, 7, 192)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 192)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 7, 7, 192)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "                                                                 activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_125 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_124 (BatchN (None, 7, 7, 192)    576         conv2d_125[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_124 (Activation)     (None, 7, 7, 192)    0           batch_normalization_124[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_126 (Conv2D)             (None, 7, 7, 192)    258048      activation_124[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_125 (BatchN (None, 7, 7, 192)    576         conv2d_126[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_125 (Activation)     (None, 7, 7, 192)    0           batch_normalization_125[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_123 (Conv2D)             (None, 7, 7, 192)    147456      mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_127 (Conv2D)             (None, 7, 7, 192)    258048      activation_125[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_122 (BatchN (None, 7, 7, 192)    576         conv2d_123[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_126 (BatchN (None, 7, 7, 192)    576         conv2d_127[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_122 (Activation)     (None, 7, 7, 192)    0           batch_normalization_122[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_126 (Activation)     (None, 7, 7, 192)    0           batch_normalization_126[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_124 (Conv2D)             (None, 3, 3, 320)    552960      activation_122[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_128 (Conv2D)             (None, 3, 3, 192)    331776      activation_126[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_123 (BatchN (None, 3, 3, 320)    960         conv2d_124[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_127 (BatchN (None, 3, 3, 192)    576         conv2d_128[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_123 (Activation)     (None, 3, 3, 320)    0           batch_normalization_123[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_127 (Activation)     (None, 3, 3, 192)    0           batch_normalization_127[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2D)  (None, 3, 3, 768)    0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed8 (Concatenate)            (None, 3, 3, 1280)   0           activation_123[0][0]             \n",
      "                                                                 activation_127[0][0]             \n",
      "                                                                 max_pooling2d_6[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_133 (Conv2D)             (None, 3, 3, 448)    573440      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_132 (BatchN (None, 3, 3, 448)    1344        conv2d_133[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_132 (Activation)     (None, 3, 3, 448)    0           batch_normalization_132[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_130 (Conv2D)             (None, 3, 3, 384)    491520      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_134 (Conv2D)             (None, 3, 3, 384)    1548288     activation_132[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_129 (BatchN (None, 3, 3, 384)    1152        conv2d_130[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_133 (BatchN (None, 3, 3, 384)    1152        conv2d_134[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_129 (Activation)     (None, 3, 3, 384)    0           batch_normalization_129[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_133 (Activation)     (None, 3, 3, 384)    0           batch_normalization_133[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_131 (Conv2D)             (None, 3, 3, 384)    442368      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_132 (Conv2D)             (None, 3, 3, 384)    442368      activation_129[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_135 (Conv2D)             (None, 3, 3, 384)    442368      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_136 (Conv2D)             (None, 3, 3, 384)    442368      activation_133[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_12 (AveragePo (None, 3, 3, 1280)   0           mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_129 (Conv2D)             (None, 3, 3, 320)    409600      mixed8[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_130 (BatchN (None, 3, 3, 384)    1152        conv2d_131[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_131 (BatchN (None, 3, 3, 384)    1152        conv2d_132[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_134 (BatchN (None, 3, 3, 384)    1152        conv2d_135[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_135 (BatchN (None, 3, 3, 384)    1152        conv2d_136[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_137 (Conv2D)             (None, 3, 3, 192)    245760      average_pooling2d_12[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_128 (BatchN (None, 3, 3, 320)    960         conv2d_129[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_130 (Activation)     (None, 3, 3, 384)    0           batch_normalization_130[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_131 (Activation)     (None, 3, 3, 384)    0           batch_normalization_131[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_134 (Activation)     (None, 3, 3, 384)    0           batch_normalization_134[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_135 (Activation)     (None, 3, 3, 384)    0           batch_normalization_135[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_136 (BatchN (None, 3, 3, 192)    576         conv2d_137[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_128 (Activation)     (None, 3, 3, 320)    0           batch_normalization_128[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_0 (Concatenate)          (None, 3, 3, 768)    0           activation_130[0][0]             \n",
      "                                                                 activation_131[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 3, 3, 768)    0           activation_134[0][0]             \n",
      "                                                                 activation_135[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_136 (Activation)     (None, 3, 3, 192)    0           batch_normalization_136[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9 (Concatenate)            (None, 3, 3, 2048)   0           activation_128[0][0]             \n",
      "                                                                 mixed9_0[0][0]                   \n",
      "                                                                 concatenate[0][0]                \n",
      "                                                                 activation_136[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_142 (Conv2D)             (None, 3, 3, 448)    917504      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_141 (BatchN (None, 3, 3, 448)    1344        conv2d_142[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 3, 3, 448)    0           batch_normalization_141[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_139 (Conv2D)             (None, 3, 3, 384)    786432      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_143 (Conv2D)             (None, 3, 3, 384)    1548288     activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_138 (BatchN (None, 3, 3, 384)    1152        conv2d_139[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_142 (BatchN (None, 3, 3, 384)    1152        conv2d_143[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_138 (Activation)     (None, 3, 3, 384)    0           batch_normalization_138[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 3, 3, 384)    0           batch_normalization_142[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_140 (Conv2D)             (None, 3, 3, 384)    442368      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_141 (Conv2D)             (None, 3, 3, 384)    442368      activation_138[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_144 (Conv2D)             (None, 3, 3, 384)    442368      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_145 (Conv2D)             (None, 3, 3, 384)    442368      activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_13 (AveragePo (None, 3, 3, 2048)   0           mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_138 (Conv2D)             (None, 3, 3, 320)    655360      mixed9[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_139 (BatchN (None, 3, 3, 384)    1152        conv2d_140[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_140 (BatchN (None, 3, 3, 384)    1152        conv2d_141[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_143 (BatchN (None, 3, 3, 384)    1152        conv2d_144[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_144 (BatchN (None, 3, 3, 384)    1152        conv2d_145[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_146 (Conv2D)             (None, 3, 3, 192)    393216      average_pooling2d_13[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_137 (BatchN (None, 3, 3, 320)    960         conv2d_138[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 3, 3, 384)    0           batch_normalization_139[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 3, 3, 384)    0           batch_normalization_140[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 3, 3, 384)    0           batch_normalization_143[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 3, 3, 384)    0           batch_normalization_144[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_145 (BatchN (None, 3, 3, 192)    576         conv2d_146[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_137 (Activation)     (None, 3, 3, 320)    0           batch_normalization_137[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_139[0][0]             \n",
      "                                                                 activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 3, 3, 768)    0           activation_143[0][0]             \n",
      "                                                                 activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 3, 3, 192)    0           batch_normalization_145[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_137[0][0]             \n",
      "                                                                 mixed9_1[0][0]                   \n",
      "                                                                 concatenate_1[0][0]              \n",
      "                                                                 activation_145[0][0]             \n",
      "==================================================================================================\n",
      "Total params: 21,802,784\n",
      "Trainable params: 21,768,352\n",
      "Non-trainable params: 34,432\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "path_inception = f\"{getcwd()}/../tmp2/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    "\n",
    "# Import the inception model  \n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "# Create an instance of the inception model from the local pre-trained weights\n",
    "local_weights_file = path_inception\n",
    "\n",
    "pre_trained_model = InceptionV3(input_shape = (150,150,3),\n",
    "                                include_top = False,\n",
    "                                weights = None)\n",
    "\n",
    "pre_trained_model.load_weights(local_weights_file)\n",
    "\n",
    "# Make all the layers in the pre-trained model non-trainable\n",
    "for layer in pre_trained_model.layers:\n",
    "    layer.trainables = False\n",
    "  \n",
    "# Print the model summary\n",
    "pre_trained_model.summary()\n",
    "\n",
    "# Expected Output is extremely large, but should end with:\n",
    "\n",
    "#batch_normalization_v1_281 (Bat (None, 3, 3, 192)    576         conv2d_281[0][0]                 \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_273 (Activation)     (None, 3, 3, 320)    0           batch_normalization_v1_273[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed9_1 (Concatenate)          (None, 3, 3, 768)    0           activation_275[0][0]             \n",
    "#                                                                 activation_276[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#concatenate_5 (Concatenate)     (None, 3, 3, 768)    0           activation_279[0][0]             \n",
    "#                                                                 activation_280[0][0]             \n",
    "#__________________________________________________________________________________________________\n",
    "#activation_281 (Activation)     (None, 3, 3, 192)    0           batch_normalization_v1_281[0][0] \n",
    "#__________________________________________________________________________________________________\n",
    "#mixed10 (Concatenate)           (None, 3, 3, 2048)   0           activation_273[0][0]             \n",
    "#                                                                 mixed9_1[0][0]                   \n",
    "#                                                                 concatenate_5[0][0]              \n",
    "#                                                                 activation_281[0][0]             \n",
    "#==================================================================================================\n",
    "#Total params: 21,802,784\n",
    "#Trainable params: 0\n",
    "#Non-trainable params: 21,802,784"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "CFsUlwdfs_wg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "last layer output shape:  (None, 7, 7, 768)\n"
     ]
    }
   ],
   "source": [
    "last_layer = pre_trained_model.get_layer('mixed7')\n",
    "print('last layer output shape: ', last_layer.output_shape)\n",
    "last_output = last_layer.output\n",
    "\n",
    "# Expected Output:\n",
    "# ('last layer output shape: ', (None, 7, 7, 768))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "-bsWZWp5oMq9"
   },
   "outputs": [],
   "source": [
    "# Define a Callback class that stops training once accuracy reaches 97.0%\n",
    "class myCallback(tf.keras.callbacks.Callback):\n",
    "  def on_epoch_end(self, epoch, logs={}):\n",
    "    if(logs.get('accuracy')>0.97):\n",
    "      print(\"\\nReached 97.0% accuracy so cancelling training!\")\n",
    "      self.model.stop_training = True\n",
    "\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "BMXb913pbvFg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 150, 150, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 74, 74, 32)   864         input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_52 (BatchNo (None, 74, 74, 32)   96          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 74, 74, 32)   0           batch_normalization_52[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_54 (Conv2D)              (None, 72, 72, 32)   9216        activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_53 (BatchNo (None, 72, 72, 32)   96          conv2d_54[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 72, 72, 32)   0           batch_normalization_53[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_55 (Conv2D)              (None, 72, 72, 64)   18432       activation_53[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_54 (BatchNo (None, 72, 72, 64)   192         conv2d_55[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 72, 72, 64)   0           batch_normalization_54[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 35, 35, 64)   0           activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_56 (Conv2D)              (None, 35, 35, 80)   5120        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_55 (BatchNo (None, 35, 35, 80)   240         conv2d_56[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 35, 35, 80)   0           batch_normalization_55[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_57 (Conv2D)              (None, 33, 33, 192)  138240      activation_55[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_56 (BatchNo (None, 33, 33, 192)  576         conv2d_57[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 33, 33, 192)  0           batch_normalization_56[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 16, 16, 192)  0           activation_56[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_61 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_60 (BatchNo (None, 16, 16, 64)   192         conv2d_61[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_60 (Activation)      (None, 16, 16, 64)   0           batch_normalization_60[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_59 (Conv2D)              (None, 16, 16, 48)   9216        max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_62 (Conv2D)              (None, 16, 16, 96)   55296       activation_60[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_58 (BatchNo (None, 16, 16, 48)   144         conv2d_59[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_61 (BatchNo (None, 16, 16, 96)   288         conv2d_62[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_58 (Activation)      (None, 16, 16, 48)   0           batch_normalization_58[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_61 (Activation)      (None, 16, 16, 96)   0           batch_normalization_61[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_5 (AveragePoo (None, 16, 16, 192)  0           max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_58 (Conv2D)              (None, 16, 16, 64)   12288       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_60 (Conv2D)              (None, 16, 16, 64)   76800       activation_58[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_63 (Conv2D)              (None, 16, 16, 96)   82944       activation_61[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_64 (Conv2D)              (None, 16, 16, 32)   6144        average_pooling2d_5[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_57 (BatchNo (None, 16, 16, 64)   192         conv2d_58[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_59 (BatchNo (None, 16, 16, 64)   192         conv2d_60[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_62 (BatchNo (None, 16, 16, 96)   288         conv2d_63[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_63 (BatchNo (None, 16, 16, 32)   96          conv2d_64[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_57 (Activation)      (None, 16, 16, 64)   0           batch_normalization_57[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_59 (Activation)      (None, 16, 16, 64)   0           batch_normalization_59[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_62 (Activation)      (None, 16, 16, 96)   0           batch_normalization_62[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_63 (Activation)      (None, 16, 16, 32)   0           batch_normalization_63[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed0 (Concatenate)            (None, 16, 16, 256)  0           activation_57[0][0]              \n",
      "                                                                 activation_59[0][0]              \n",
      "                                                                 activation_62[0][0]              \n",
      "                                                                 activation_63[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_68 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_67 (BatchNo (None, 16, 16, 64)   192         conv2d_68[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_67 (Activation)      (None, 16, 16, 64)   0           batch_normalization_67[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_66 (Conv2D)              (None, 16, 16, 48)   12288       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_69 (Conv2D)              (None, 16, 16, 96)   55296       activation_67[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_65 (BatchNo (None, 16, 16, 48)   144         conv2d_66[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_68 (BatchNo (None, 16, 16, 96)   288         conv2d_69[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_65 (Activation)      (None, 16, 16, 48)   0           batch_normalization_65[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_68 (Activation)      (None, 16, 16, 96)   0           batch_normalization_68[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_6 (AveragePoo (None, 16, 16, 256)  0           mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_65 (Conv2D)              (None, 16, 16, 64)   16384       mixed0[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_67 (Conv2D)              (None, 16, 16, 64)   76800       activation_65[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_70 (Conv2D)              (None, 16, 16, 96)   82944       activation_68[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_71 (Conv2D)              (None, 16, 16, 64)   16384       average_pooling2d_6[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_64 (BatchNo (None, 16, 16, 64)   192         conv2d_65[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_66 (BatchNo (None, 16, 16, 64)   192         conv2d_67[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_69 (BatchNo (None, 16, 16, 96)   288         conv2d_70[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_70 (BatchNo (None, 16, 16, 64)   192         conv2d_71[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_64 (Activation)      (None, 16, 16, 64)   0           batch_normalization_64[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_66 (Activation)      (None, 16, 16, 64)   0           batch_normalization_66[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_69 (Activation)      (None, 16, 16, 96)   0           batch_normalization_69[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_70 (Activation)      (None, 16, 16, 64)   0           batch_normalization_70[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed1 (Concatenate)            (None, 16, 16, 288)  0           activation_64[0][0]              \n",
      "                                                                 activation_66[0][0]              \n",
      "                                                                 activation_69[0][0]              \n",
      "                                                                 activation_70[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_75 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_74 (BatchNo (None, 16, 16, 64)   192         conv2d_75[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_74 (Activation)      (None, 16, 16, 64)   0           batch_normalization_74[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_73 (Conv2D)              (None, 16, 16, 48)   13824       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_76 (Conv2D)              (None, 16, 16, 96)   55296       activation_74[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_72 (BatchNo (None, 16, 16, 48)   144         conv2d_73[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_75 (BatchNo (None, 16, 16, 96)   288         conv2d_76[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_72 (Activation)      (None, 16, 16, 48)   0           batch_normalization_72[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_75 (Activation)      (None, 16, 16, 96)   0           batch_normalization_75[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_7 (AveragePoo (None, 16, 16, 288)  0           mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_72 (Conv2D)              (None, 16, 16, 64)   18432       mixed1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_74 (Conv2D)              (None, 16, 16, 64)   76800       activation_72[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_77 (Conv2D)              (None, 16, 16, 96)   82944       activation_75[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_78 (Conv2D)              (None, 16, 16, 64)   18432       average_pooling2d_7[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_71 (BatchNo (None, 16, 16, 64)   192         conv2d_72[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_73 (BatchNo (None, 16, 16, 64)   192         conv2d_74[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_76 (BatchNo (None, 16, 16, 96)   288         conv2d_77[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_77 (BatchNo (None, 16, 16, 64)   192         conv2d_78[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_71 (Activation)      (None, 16, 16, 64)   0           batch_normalization_71[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_73 (Activation)      (None, 16, 16, 64)   0           batch_normalization_73[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_76 (Activation)      (None, 16, 16, 96)   0           batch_normalization_76[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_77 (Activation)      (None, 16, 16, 64)   0           batch_normalization_77[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed2 (Concatenate)            (None, 16, 16, 288)  0           activation_71[0][0]              \n",
      "                                                                 activation_73[0][0]              \n",
      "                                                                 activation_76[0][0]              \n",
      "                                                                 activation_77[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_80 (Conv2D)              (None, 16, 16, 64)   18432       mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_79 (BatchNo (None, 16, 16, 64)   192         conv2d_80[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_79 (Activation)      (None, 16, 16, 64)   0           batch_normalization_79[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_81 (Conv2D)              (None, 16, 16, 96)   55296       activation_79[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_80 (BatchNo (None, 16, 16, 96)   288         conv2d_81[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_80 (Activation)      (None, 16, 16, 96)   0           batch_normalization_80[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_79 (Conv2D)              (None, 7, 7, 384)    995328      mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_82 (Conv2D)              (None, 7, 7, 96)     82944       activation_80[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_78 (BatchNo (None, 7, 7, 384)    1152        conv2d_79[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_81 (BatchNo (None, 7, 7, 96)     288         conv2d_82[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_78 (Activation)      (None, 7, 7, 384)    0           batch_normalization_78[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_81 (Activation)      (None, 7, 7, 96)     0           batch_normalization_81[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2D)  (None, 7, 7, 288)    0           mixed2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "mixed3 (Concatenate)            (None, 7, 7, 768)    0           activation_78[0][0]              \n",
      "                                                                 activation_81[0][0]              \n",
      "                                                                 max_pooling2d_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_87 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_86 (BatchNo (None, 7, 7, 128)    384         conv2d_87[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_86 (Activation)      (None, 7, 7, 128)    0           batch_normalization_86[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_88 (Conv2D)              (None, 7, 7, 128)    114688      activation_86[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_87 (BatchNo (None, 7, 7, 128)    384         conv2d_88[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_87 (Activation)      (None, 7, 7, 128)    0           batch_normalization_87[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_84 (Conv2D)              (None, 7, 7, 128)    98304       mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_89 (Conv2D)              (None, 7, 7, 128)    114688      activation_87[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_83 (BatchNo (None, 7, 7, 128)    384         conv2d_84[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_88 (BatchNo (None, 7, 7, 128)    384         conv2d_89[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_83 (Activation)      (None, 7, 7, 128)    0           batch_normalization_83[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_88 (Activation)      (None, 7, 7, 128)    0           batch_normalization_88[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_85 (Conv2D)              (None, 7, 7, 128)    114688      activation_83[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_90 (Conv2D)              (None, 7, 7, 128)    114688      activation_88[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_84 (BatchNo (None, 7, 7, 128)    384         conv2d_85[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_89 (BatchNo (None, 7, 7, 128)    384         conv2d_90[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_84 (Activation)      (None, 7, 7, 128)    0           batch_normalization_84[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_89 (Activation)      (None, 7, 7, 128)    0           batch_normalization_89[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 7, 7, 768)    0           mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_83 (Conv2D)              (None, 7, 7, 192)    147456      mixed3[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_86 (Conv2D)              (None, 7, 7, 192)    172032      activation_84[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_91 (Conv2D)              (None, 7, 7, 192)    172032      activation_89[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_92 (Conv2D)              (None, 7, 7, 192)    147456      average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_82 (BatchNo (None, 7, 7, 192)    576         conv2d_83[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_85 (BatchNo (None, 7, 7, 192)    576         conv2d_86[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_90 (BatchNo (None, 7, 7, 192)    576         conv2d_91[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_91 (BatchNo (None, 7, 7, 192)    576         conv2d_92[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_82 (Activation)      (None, 7, 7, 192)    0           batch_normalization_82[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_85 (Activation)      (None, 7, 7, 192)    0           batch_normalization_85[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_90 (Activation)      (None, 7, 7, 192)    0           batch_normalization_90[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_91 (Activation)      (None, 7, 7, 192)    0           batch_normalization_91[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "mixed4 (Concatenate)            (None, 7, 7, 768)    0           activation_82[0][0]              \n",
      "                                                                 activation_85[0][0]              \n",
      "                                                                 activation_90[0][0]              \n",
      "                                                                 activation_91[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_97 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_96 (BatchNo (None, 7, 7, 160)    480         conv2d_97[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_96 (Activation)      (None, 7, 7, 160)    0           batch_normalization_96[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_98 (Conv2D)              (None, 7, 7, 160)    179200      activation_96[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_97 (BatchNo (None, 7, 7, 160)    480         conv2d_98[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_97 (Activation)      (None, 7, 7, 160)    0           batch_normalization_97[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_94 (Conv2D)              (None, 7, 7, 160)    122880      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_99 (Conv2D)              (None, 7, 7, 160)    179200      activation_97[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_93 (BatchNo (None, 7, 7, 160)    480         conv2d_94[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_98 (BatchNo (None, 7, 7, 160)    480         conv2d_99[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_93 (Activation)      (None, 7, 7, 160)    0           batch_normalization_93[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_98 (Activation)      (None, 7, 7, 160)    0           batch_normalization_98[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_95 (Conv2D)              (None, 7, 7, 160)    179200      activation_93[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_100 (Conv2D)             (None, 7, 7, 160)    179200      activation_98[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_94 (BatchNo (None, 7, 7, 160)    480         conv2d_95[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_99 (BatchNo (None, 7, 7, 160)    480         conv2d_100[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_94 (Activation)      (None, 7, 7, 160)    0           batch_normalization_94[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_99 (Activation)      (None, 7, 7, 160)    0           batch_normalization_99[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_9 (AveragePoo (None, 7, 7, 768)    0           mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_93 (Conv2D)              (None, 7, 7, 192)    147456      mixed4[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_96 (Conv2D)              (None, 7, 7, 192)    215040      activation_94[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_101 (Conv2D)             (None, 7, 7, 192)    215040      activation_99[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_102 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_9[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_92 (BatchNo (None, 7, 7, 192)    576         conv2d_93[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_95 (BatchNo (None, 7, 7, 192)    576         conv2d_96[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_100 (BatchN (None, 7, 7, 192)    576         conv2d_101[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_101 (BatchN (None, 7, 7, 192)    576         conv2d_102[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_92 (Activation)      (None, 7, 7, 192)    0           batch_normalization_92[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_95 (Activation)      (None, 7, 7, 192)    0           batch_normalization_95[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_100 (Activation)     (None, 7, 7, 192)    0           batch_normalization_100[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_101 (Activation)     (None, 7, 7, 192)    0           batch_normalization_101[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed5 (Concatenate)            (None, 7, 7, 768)    0           activation_92[0][0]              \n",
      "                                                                 activation_95[0][0]              \n",
      "                                                                 activation_100[0][0]             \n",
      "                                                                 activation_101[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_107 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_106 (BatchN (None, 7, 7, 160)    480         conv2d_107[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_106 (Activation)     (None, 7, 7, 160)    0           batch_normalization_106[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_108 (Conv2D)             (None, 7, 7, 160)    179200      activation_106[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_107 (BatchN (None, 7, 7, 160)    480         conv2d_108[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_107 (Activation)     (None, 7, 7, 160)    0           batch_normalization_107[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_104 (Conv2D)             (None, 7, 7, 160)    122880      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_109 (Conv2D)             (None, 7, 7, 160)    179200      activation_107[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_103 (BatchN (None, 7, 7, 160)    480         conv2d_104[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_108 (BatchN (None, 7, 7, 160)    480         conv2d_109[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_103 (Activation)     (None, 7, 7, 160)    0           batch_normalization_103[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_108 (Activation)     (None, 7, 7, 160)    0           batch_normalization_108[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_105 (Conv2D)             (None, 7, 7, 160)    179200      activation_103[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_110 (Conv2D)             (None, 7, 7, 160)    179200      activation_108[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_104 (BatchN (None, 7, 7, 160)    480         conv2d_105[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_109 (BatchN (None, 7, 7, 160)    480         conv2d_110[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_104 (Activation)     (None, 7, 7, 160)    0           batch_normalization_104[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_109 (Activation)     (None, 7, 7, 160)    0           batch_normalization_109[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 7, 7, 768)    0           mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_103 (Conv2D)             (None, 7, 7, 192)    147456      mixed5[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_106 (Conv2D)             (None, 7, 7, 192)    215040      activation_104[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_111 (Conv2D)             (None, 7, 7, 192)    215040      activation_109[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_112 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_102 (BatchN (None, 7, 7, 192)    576         conv2d_103[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_105 (BatchN (None, 7, 7, 192)    576         conv2d_106[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_110 (BatchN (None, 7, 7, 192)    576         conv2d_111[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_111 (BatchN (None, 7, 7, 192)    576         conv2d_112[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_102 (Activation)     (None, 7, 7, 192)    0           batch_normalization_102[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_105 (Activation)     (None, 7, 7, 192)    0           batch_normalization_105[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_110 (Activation)     (None, 7, 7, 192)    0           batch_normalization_110[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_111 (Activation)     (None, 7, 7, 192)    0           batch_normalization_111[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed6 (Concatenate)            (None, 7, 7, 768)    0           activation_102[0][0]             \n",
      "                                                                 activation_105[0][0]             \n",
      "                                                                 activation_110[0][0]             \n",
      "                                                                 activation_111[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_117 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_116 (BatchN (None, 7, 7, 192)    576         conv2d_117[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_116 (Activation)     (None, 7, 7, 192)    0           batch_normalization_116[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_118 (Conv2D)             (None, 7, 7, 192)    258048      activation_116[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_117 (BatchN (None, 7, 7, 192)    576         conv2d_118[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_117 (Activation)     (None, 7, 7, 192)    0           batch_normalization_117[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_114 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_119 (Conv2D)             (None, 7, 7, 192)    258048      activation_117[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_113 (BatchN (None, 7, 7, 192)    576         conv2d_114[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_118 (BatchN (None, 7, 7, 192)    576         conv2d_119[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_113 (Activation)     (None, 7, 7, 192)    0           batch_normalization_113[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_118 (Activation)     (None, 7, 7, 192)    0           batch_normalization_118[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_115 (Conv2D)             (None, 7, 7, 192)    258048      activation_113[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_120 (Conv2D)             (None, 7, 7, 192)    258048      activation_118[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_114 (BatchN (None, 7, 7, 192)    576         conv2d_115[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_119 (BatchN (None, 7, 7, 192)    576         conv2d_120[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_114 (Activation)     (None, 7, 7, 192)    0           batch_normalization_114[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_119 (Activation)     (None, 7, 7, 192)    0           batch_normalization_119[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_11 (AveragePo (None, 7, 7, 768)    0           mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_113 (Conv2D)             (None, 7, 7, 192)    147456      mixed6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_116 (Conv2D)             (None, 7, 7, 192)    258048      activation_114[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_121 (Conv2D)             (None, 7, 7, 192)    258048      activation_119[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_122 (Conv2D)             (None, 7, 7, 192)    147456      average_pooling2d_11[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_112 (BatchN (None, 7, 7, 192)    576         conv2d_113[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_115 (BatchN (None, 7, 7, 192)    576         conv2d_116[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_120 (BatchN (None, 7, 7, 192)    576         conv2d_121[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_121 (BatchN (None, 7, 7, 192)    576         conv2d_122[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_112 (Activation)     (None, 7, 7, 192)    0           batch_normalization_112[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_115 (Activation)     (None, 7, 7, 192)    0           batch_normalization_115[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_120 (Activation)     (None, 7, 7, 192)    0           batch_normalization_120[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_121 (Activation)     (None, 7, 7, 192)    0           batch_normalization_121[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_112[0][0]             \n",
      "                                                                 activation_115[0][0]             \n",
      "                                                                 activation_120[0][0]             \n",
      "                                                                 activation_121[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "flatten (Flatten)               (None, 37632)        0           mixed7[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 1024)         38536192    flatten[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout (Dropout)               (None, 1024)         0           dense[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 1)            1025        dropout[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 47,512,481\n",
      "Trainable params: 47,493,665\n",
      "Non-trainable params: 18,816\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "\n",
    "# Flatten the output layer to 1 dimension\n",
    "x = layers.Flatten()(last_output)\n",
    "# Add a fully connected layer with 1,024 hidden units and ReLU activation\n",
    "x = layers.Dense(1024, activation='relu')(x)\n",
    "# Add a dropout rate of 0.2\n",
    "x = layers.Dropout(0.2)(x)                  \n",
    "# Add a final sigmoid layer for classification\n",
    "x = layers.Dense  (1, activation='sigmoid')(x)           \n",
    "\n",
    "model = Model(pre_trained_model.input, x) \n",
    "\n",
    "model.compile(optimizer = RMSprop(lr=0.0001), \n",
    "              loss = 'binary_crossentropy', \n",
    "              metrics = ['accuracy'])\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# Expected output will be large. Last few lines should be:\n",
    "\n",
    "# mixed7 (Concatenate)            (None, 7, 7, 768)    0           activation_248[0][0]             \n",
    "#                                                                  activation_251[0][0]             \n",
    "#                                                                  activation_256[0][0]             \n",
    "#                                                                  activation_257[0][0]             \n",
    "# __________________________________________________________________________________________________\n",
    "# flatten_4 (Flatten)             (None, 37632)        0           mixed7[0][0]                     \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_8 (Dense)                 (None, 1024)         38536192    flatten_4[0][0]                  \n",
    "# __________________________________________________________________________________________________\n",
    "# dropout_4 (Dropout)             (None, 1024)         0           dense_8[0][0]                    \n",
    "# __________________________________________________________________________________________________\n",
    "# dense_9 (Dense)                 (None, 1)            1025        dropout_4[0][0]                  \n",
    "# ==================================================================================================\n",
    "# Total params: 47,512,481\n",
    "# Trainable params: 38,537,217\n",
    "# Non-trainable params: 8,975,264\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HrnL_IQ8knWA"
   },
   "outputs": [],
   "source": [
    "# Get the Horse or Human dataset\n",
    "path_horse_or_human = f\"{getcwd()}/../tmp2/horse-or-human.zip\"\n",
    "# Get the Horse or Human Validation dataset\n",
    "path_validation_horse_or_human = f\"{getcwd()}/../tmp2/validation-horse-or-human.zip\"\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "import os\n",
    "import zipfile\n",
    "import shutil\n",
    "\n",
    "shutil.rmtree('/tmp')\n",
    "local_zip = path_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/training')\n",
    "zip_ref.close()\n",
    "\n",
    "local_zip = path_validation_horse_or_human\n",
    "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
    "zip_ref.extractall('/tmp/validation')\n",
    "zip_ref.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "y9okX7_ovskI"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n",
      "527\n",
      "128\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "# Define our example directories and files\n",
    "train_dir = '/tmp/training'\n",
    "validation_dir = '/tmp/validation'\n",
    "\n",
    "train_horses_dir = os.path.join(train_dir, 'horses')\n",
    "train_humans_dir = os.path.join(train_dir, 'humans')\n",
    "validation_horses_dir = os.path.join(validation_dir, 'horses')\n",
    "validation_humans_dir = os.path.join(validation_dir, 'humans')\n",
    "\n",
    "train_horses_fnames = os.listdir(train_horses_dir)\n",
    "train_humans_fnames = os.listdir(train_humans_dir)\n",
    "validation_horses_fnames = os.listdir(validation_horses_dir)\n",
    "validation_humans_fnames = os.listdir(validation_humans_dir)\n",
    "\n",
    "print(len(train_horses_fnames))\n",
    "print(len(train_humans_fnames))\n",
    "print(len(validation_horses_fnames))\n",
    "print(len(validation_humans_fnames))\n",
    "\n",
    "# Expected Output:\n",
    "# 500\n",
    "# 527\n",
    "# 128\n",
    "# 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "O4s8HckqGlnb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1027 images belonging to 2 classes.\n",
      "Found 256 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Add our data-augmentation parameters to ImageDataGenerator\n",
    "train_datagen = ImageDataGenerator(\n",
    "                rescale=1/255,\n",
    "                rotation_range=40, \n",
    "                width_shift_range = 0.3,\n",
    "                height_shift_range = 0.3,\n",
    "                shear_range=0.3, \n",
    "                zoom_range=0.3,\n",
    "                horizontal_flip=True)\n",
    "\n",
    "# Note that the validation data should not be augmented!\n",
    "test_datagen = ImageDataGenerator(rescale=1/255)\n",
    "\n",
    "# Flow training images in batches of 20 using train_datagen generator\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode = 'binary')     \n",
    "\n",
    "# Flow validation images in batches of 20 using test_datagen generator\n",
    "validation_generator =  test_datagen.flow_from_directory(\n",
    "    validation_dir,\n",
    "    target_size=(150,150),\n",
    "    batch_size=20,\n",
    "    class_mode= 'binary')\n",
    "\n",
    "# Expected Output:\n",
    "# Found 1027 images belonging to 2 classes.\n",
    "# Found 256 images belonging to 2 classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Blhq2MAUeyGA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      " 99/100 [============================>.] - ETA: 1s - loss: 0.0056 - accuracy: 0.9985\n",
      "Reached 97.0% accuracy so cancelling training!\n",
      "100/100 [==============================] - 115s 1s/step - loss: 0.0056 - accuracy: 0.9985 - val_loss: 0.1584 - val_accuracy: 0.9773\n"
     ]
    }
   ],
   "source": [
    "# Run this and see how many epochs it should take before the callback\n",
    "# fires, and stops training at 97% accuracy\n",
    "\n",
    "callbacks = myCallback()\n",
    "history = model.fit_generator(\n",
    "                    train_generator,\n",
    "                    validation_data = validation_generator,\n",
    "                    steps_per_epoch = 100,\n",
    "                    epochs = 3,\n",
    "                    validation_steps = 20,\n",
    "                    verbose = 1,\n",
    "                    callbacks=[callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C2Fp6Se9rKuL"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs = range(len(acc))\n",
    "\n",
    "plt.plot(epochs, acc, 'r', label='Training accuracy')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.legend(loc=0)\n",
    "plt.figure()\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submission Instructions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now click the 'Submit Assignment' button above."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# When you're done or would like to take a break, please run the two cells below to save your work and close the Notebook. This will free up resources for your fellow learners. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "<!-- Save the notebook -->\n",
    "IPython.notebook.save_checkpoint();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%javascript\n",
    "IPython.notebook.session.delete();\n",
    "window.onbeforeunload = null\n",
    "setTimeout(function() { window.close(); }, 1000);"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Exercise 7 - Question.ipynb",
   "provenance": []
  },
  "coursera": {
   "course_slug": "convolutional-neural-networks-tensorflow",
   "graded_item_id": "csg1x",
   "launcher_item_id": "GpKYz"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
